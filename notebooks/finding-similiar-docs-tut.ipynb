{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit more philosophically, you can think of each number in the vector as a coordinate in an N-dimensional space (where N is the length of the vector). The working assumption here is that, **if the transformer learned a useful representation of the document, similar documents will live close together in that N-dimensional space.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "documents = [\n",
    "    \"That restaurant was not as good as the last movie I watched.\",\n",
    "    \"I'm selling a used car in good condition\",\n",
    "    \"Food was okay, the rest so so\",\n",
    "    \"I love cats, but don't really like hyenas\",\n",
    "    \"On the road, you must be careful\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([15, 768]),\n",
       " torch.Size([12, 768]),\n",
       " torch.Size([10, 768]),\n",
       " torch.Size([15, 768]),\n",
       " torch.Size([10, 768])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = [\n",
    "  # tokenize the document, return it as PyTorch tensors (vectors),\n",
    "  # and pass it onto the model\n",
    "  model(**tokenizer(document, return_tensors='pt'))[0].detach().squeeze()\n",
    "  for document in documents\n",
    "]\n",
    "\n",
    "[v.size() for v in vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avg representation\n",
    "averaged_vectors = [torch.mean(vector, dim=0) for vector in vectors]\n",
    "[v.size() for v in averaged_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(document: str) -> torch.Tensor:\n",
    "    \"\"\"this function will return a transformer representation of the doc\"\"\"\n",
    "    tokens = tokenizer(document, return_tensors='pt')\n",
    "    vector = model(**tokens)[0].detach().squeeze()\n",
    "    return torch.mean(vector, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
    "index.add_with_ids(\n",
    "    np.array([t.numpy() for t in averaged_vectors]),\n",
    "    np.array(range(0, len(documents)))\n",
    ")\n",
    "\n",
    "def search(query: str, k=1):\n",
    "    encoded_query = encode(query).unsqueeze(dim=0).numpy()\n",
    "    top_k = index.search(encoded_query, k)\n",
    "    scores = top_k[0][0]\n",
    "    results = [documents[_id] for _id in top_k[1][0]]\n",
    "    return list(zip(results, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm selling a used car in good condition\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"I'm selling a used car in good condition\", 70.69185),\n",
       " ('On the road, you must be careful', 53.795795)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(documents[1], k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('On the road, you must be careful', 54.49833)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('I know how to drive', k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexIDMap; proxy of <Swig Object of type 'faiss::IndexIDMapTemplate< faiss::Index > *' at 0x7fda0332be40> >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('live-project-nlp-text-search-BVZrNjpK')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "278c8a15424c1bdb670dced171f3ac89591734fb1541895bf200056ef77f0fe7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
